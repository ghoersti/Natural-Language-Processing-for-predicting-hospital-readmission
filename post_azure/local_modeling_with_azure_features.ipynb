{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## local Modeling \n",
    "\n",
    "start with \n",
    "\n",
    "```python\n",
    "'Tokens_vectors_text/Data_for_modeling.parquet'\n",
    "```\n",
    "\n",
    "> this data has been processed in azure and contains the data and feature vectors ready to model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T03:24:27.617139Z",
     "start_time": "2018-11-12T03:24:27.589068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ucsddse230/work/final_project/post_azure'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T03:25:13.254773Z",
     "start_time": "2018-11-12T03:25:12.848870Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.ml.feature \n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "import pyspark.sql.functions  as psf\n",
    "from pyspark.sql import Window \n",
    "from pyspark.sql.types  import DateType\n",
    "import pandas as pd\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "from pyspark.sql.types import Row, StructField, StructType, StringType, IntegerType , DateType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T03:25:15.870265Z",
     "start_time": "2018-11-12T03:25:14.309790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[4] appName=pyspark-shell>\n"
     ]
    }
   ],
   "source": [
    "#sc.stop()\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import Row, StructField, StructType, StringType, IntegerType , DateType, ArrayType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext ,SparkConf\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '6g')\n",
    "#SparkContext.setSystemProperty('spark.rdd.compress', True)\n",
    "SparkContext.setSystemProperty('spark.driver.memory', '16g')\n",
    "sc = SparkContext(master=\"local[4]\")\n",
    "print(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T03:25:17.726101Z",
     "start_time": "2018-11-12T03:25:17.690639Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, LinearSVC,NaiveBayes\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T03:25:19.399517Z",
     "start_time": "2018-11-12T03:25:19.394351Z"
    }
   },
   "outputs": [],
   "source": [
    "path='/home/ucsddse230/work/final_project/azure/Tokens_vectors_text/Data_for_modeling.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T03:25:20.816479Z",
     "start_time": "2018-11-12T03:25:20.749940Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T03:25:24.333421Z",
     "start_time": "2018-11-12T03:25:22.366146Z"
    }
   },
   "outputs": [],
   "source": [
    "model_data= spark.read.parquet(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## happy modeling\n",
    ">please explore the the multilayer perceptron here and many others\n",
    "https://spark.apache.org/docs/2.3.0/ml-classification-regression.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T02:58:30.919483Z",
     "start_time": "2018-11-12T02:58:30.890629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HADM_ID', 'int'),\n",
       " ('SUBJECT_ID', 'int'),\n",
       " ('ADMITTIME', 'timestamp'),\n",
       " ('DISCHTIME', 'timestamp'),\n",
       " ('DEATHTIME', 'timestamp'),\n",
       " ('ADMISSION_TYPE', 'string'),\n",
       " ('NEXT_ADMISSION', 'timestamp'),\n",
       " ('NEXT_ADMISSION_TYPE', 'string'),\n",
       " ('days_next_admit', 'int'),\n",
       " ('CATEGORY', 'string'),\n",
       " ('tokens_clean', 'array<string>'),\n",
       " ('label', 'int'),\n",
       " ('features', 'vector')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
