{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and validate final model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:04.264746Z",
     "start_time": "2018-12-05T23:44:04.228400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ucsddse230/work/final_project/post_azure'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:05.180292Z",
     "start_time": "2018-12-05T23:44:04.267839Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.ml.feature \n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "import pyspark.sql.functions  as psf\n",
    "from pyspark.sql import Window \n",
    "from pyspark.sql.types  import DateType\n",
    "import pandas as pd\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "from pyspark.sql.types import Row, StructField, StructType, StringType, IntegerType , DateType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:09.931067Z",
     "start_time": "2018-12-05T23:44:05.183527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[4] appName=pyspark-shell>\n"
     ]
    }
   ],
   "source": [
    "#sc.stop()\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import Row, StructField, StructType, StringType, IntegerType , DateType, ArrayType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext ,SparkConf\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '6g')\n",
    "#SparkContext.setSystemProperty('spark.rdd.compress', True)\n",
    "SparkContext.setSystemProperty('spark.driver.memory', '16g')\n",
    "sc = SparkContext(master=\"local[4]\")\n",
    "print(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:10.015280Z",
     "start_time": "2018-12-05T23:44:09.936435Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, LinearSVC,NaiveBayes\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:10.030772Z",
     "start_time": "2018-12-05T23:44:10.018573Z"
    }
   },
   "outputs": [],
   "source": [
    "save_file = 'MyMLP.pth'\n",
    "train_path='/home/ucsddse230/work/final_project/post_azure/training_features.parquet'\n",
    "test_path='/home/ucsddse230/work/final_project/post_azure/testing_features.parquet'\n",
    "dl_path='/home/ucsddse230/work/final_project/dl_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:10.197503Z",
     "start_time": "2018-12-05T23:44:10.040574Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:15.189674Z",
     "start_time": "2018-12-05T23:44:10.207390Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data= spark.read.parquet(train_path)\n",
    "test_data= spark.read.parquet(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## happy modeling\n",
    ">please explore the the multilayer perceptron here and many others\n",
    "https://spark.apache.org/docs/2.3.0/ml-classification-regression.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:15.277078Z",
     "start_time": "2018-12-05T23:44:15.195535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HADM_ID', 'SUBJECT_ID', 'label', 'tokens_clean', 'features']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:17.359006Z",
     "start_time": "2018-12-05T23:44:15.282643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40795 5\n",
      "10318 5\n"
     ]
    }
   ],
   "source": [
    "print(train_data.count(),len(train_data.columns))\n",
    "print(test_data.count(),len(test_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:19.297205Z",
     "start_time": "2018-12-05T23:44:17.362031Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_count = train_data[train_data.label==1].count()\n",
    "neg_count = train_data[train_data.label==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:19.974190Z",
     "start_time": "2018-12-05T23:44:19.300150Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import train, evaluate, display_metrics, classification_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:19.987168Z",
     "start_time": "2018-12-05T23:44:19.984869Z"
    }
   },
   "outputs": [],
   "source": [
    "#Uncomment below line to install torch\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:20.002383Z",
     "start_time": "2018-12-05T23:44:19.988983Z"
    }
   },
   "outputs": [],
   "source": [
    "#DL libraries and pandas and numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:27.026288Z",
     "start_time": "2018-12-05T23:44:20.004540Z"
    }
   },
   "outputs": [],
   "source": [
    "#Convert to Pandas dataframe\n",
    "test_df = test_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:27.043550Z",
     "start_time": "2018-12-05T23:44:27.028764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10318, 5)\n"
     ]
    }
   ],
   "source": [
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:27.066756Z",
     "start_time": "2018-12-05T23:44:27.048586Z"
    }
   },
   "outputs": [],
   "source": [
    "test_y = np.array(test_df['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:28.084428Z",
     "start_time": "2018-12-05T23:44:27.074849Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create tensor datasets for MLP\n",
    "\n",
    "\n",
    "#test dataset\n",
    "target = torch.from_numpy(test_y.astype('long')).view(-1)\n",
    "\n",
    "series = test_df['features'].apply(lambda x : np.array(x.toArray())).as_matrix().reshape(-1,1)\n",
    "features = np.apply_along_axis(lambda x : x[0], 1, series)\n",
    "test_dataset = TensorDataset(torch.from_numpy(features.astype('float32')), target)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:28.136359Z",
     "start_time": "2018-12-05T23:44:28.087608Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyMLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(4499,2056)\n",
    "        self.hidden2 = nn.Linear(2056,1028)\n",
    "        self.hidden3 = nn.Linear(1028,512)\n",
    "        self.hidden4 = nn.Linear(512,256)\n",
    "        self.hidden5 = nn.Linear(256,64)\n",
    "        self.hidden6 = nn.Linear(64,16)\n",
    "        self.out = nn.Linear(16,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.relu(self.hidden3(x))\n",
    "        x = F.relu(self.hidden4(x))\n",
    "        x = F.relu(self.hidden5(x))\n",
    "        x = F.relu(self.hidden6(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:28.171687Z",
     "start_time": "2018-12-05T23:44:28.146104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0651, 0.9349])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class_weightage = torch.tensor([pos_count/neg_count,1-pos_count/neg_count])\n",
    "print(class_weightage)\n",
    "criterion = nn.CrossEntropyLoss(class_weightage)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:28.217979Z",
     "start_time": "2018-12-05T23:44:28.184592Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load model\n",
    "best_model = torch.load(dl_path + save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:37.066518Z",
     "start_time": "2018-12-05T23:44:28.228445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/323]\tTime 0.046 (0.046)\tLoss 0.5381 (0.5381)\tAccuracy 87.000 (87.000)\n",
      "Test: [10/323]\tTime 0.028 (0.052)\tLoss 0.5674 (0.6690)\tAccuracy 93.000 (80.182)\n",
      "Test: [20/323]\tTime 0.067 (0.043)\tLoss 0.6730 (0.6562)\tAccuracy 81.000 (79.095)\n",
      "Test: [30/323]\tTime 0.035 (0.040)\tLoss 0.5315 (0.6327)\tAccuracy 87.000 (80.742)\n",
      "Test: [40/323]\tTime 0.014 (0.039)\tLoss 0.4849 (0.6403)\tAccuracy 90.000 (79.122)\n",
      "Test: [50/323]\tTime 0.041 (0.037)\tLoss 0.6920 (0.6335)\tAccuracy 78.000 (79.412)\n",
      "Test: [60/323]\tTime 0.017 (0.037)\tLoss 0.6123 (0.6339)\tAccuracy 84.000 (79.918)\n",
      "Test: [70/323]\tTime 0.032 (0.037)\tLoss 0.5975 (0.6297)\tAccuracy 90.000 (80.366)\n",
      "Test: [80/323]\tTime 0.031 (0.036)\tLoss 0.6657 (0.6282)\tAccuracy 90.000 (80.284)\n",
      "Test: [90/323]\tTime 0.015 (0.034)\tLoss 0.5658 (0.6273)\tAccuracy 81.000 (80.429)\n",
      "Test: [100/323]\tTime 0.023 (0.033)\tLoss 0.6707 (0.6289)\tAccuracy 75.000 (80.495)\n",
      "Test: [110/323]\tTime 0.029 (0.032)\tLoss 0.6581 (0.6307)\tAccuracy 90.000 (80.505)\n",
      "Test: [120/323]\tTime 0.018 (0.033)\tLoss 0.6895 (0.6296)\tAccuracy 81.000 (80.380)\n",
      "Test: [130/323]\tTime 0.014 (0.031)\tLoss 0.6939 (0.6292)\tAccuracy 81.000 (80.145)\n",
      "Test: [140/323]\tTime 0.017 (0.031)\tLoss 0.6988 (0.6288)\tAccuracy 71.000 (80.135)\n",
      "Test: [150/323]\tTime 0.045 (0.031)\tLoss 0.7283 (0.6332)\tAccuracy 81.000 (79.934)\n",
      "Test: [160/323]\tTime 0.014 (0.030)\tLoss 0.6079 (0.6331)\tAccuracy 84.000 (79.969)\n",
      "Test: [170/323]\tTime 0.065 (0.031)\tLoss 0.5279 (0.6326)\tAccuracy 81.000 (79.854)\n",
      "Test: [180/323]\tTime 0.022 (0.031)\tLoss 0.6653 (0.6324)\tAccuracy 71.000 (79.840)\n",
      "Test: [190/323]\tTime 0.014 (0.030)\tLoss 0.6262 (0.6333)\tAccuracy 90.000 (79.864)\n",
      "Test: [200/323]\tTime 0.014 (0.030)\tLoss 0.5651 (0.6349)\tAccuracy 75.000 (79.716)\n",
      "Test: [210/323]\tTime 0.014 (0.029)\tLoss 0.7459 (0.6368)\tAccuracy 71.000 (79.635)\n",
      "Test: [220/323]\tTime 0.014 (0.028)\tLoss 0.7777 (0.6394)\tAccuracy 75.000 (79.624)\n",
      "Test: [230/323]\tTime 0.015 (0.028)\tLoss 0.7664 (0.6400)\tAccuracy 68.000 (79.528)\n",
      "Test: [240/323]\tTime 0.051 (0.028)\tLoss 0.6752 (0.6394)\tAccuracy 78.000 (79.498)\n",
      "Test: [250/323]\tTime 0.027 (0.028)\tLoss 0.5084 (0.6386)\tAccuracy 87.000 (79.490)\n",
      "Test: [260/323]\tTime 0.014 (0.028)\tLoss 0.7300 (0.6375)\tAccuracy 75.000 (79.674)\n",
      "Test: [270/323]\tTime 0.031 (0.028)\tLoss 0.7659 (0.6377)\tAccuracy 75.000 (79.546)\n",
      "Test: [280/323]\tTime 0.039 (0.028)\tLoss 0.6589 (0.6386)\tAccuracy 81.000 (79.491)\n",
      "Test: [290/323]\tTime 0.028 (0.028)\tLoss 0.5784 (0.6379)\tAccuracy 90.000 (79.485)\n",
      "Test: [300/323]\tTime 0.013 (0.028)\tLoss 0.6055 (0.6383)\tAccuracy 81.000 (79.551)\n",
      "Test: [310/323]\tTime 0.014 (0.028)\tLoss 0.6195 (0.6392)\tAccuracy 75.000 (79.447)\n",
      "Test: [320/323]\tTime 0.014 (0.027)\tLoss 0.6870 (0.6389)\tAccuracy 71.000 (79.452)\n"
     ]
    }
   ],
   "source": [
    "#Test metrics\n",
    "test_loss, test_accuracy, test_results = evaluate(best_model, device, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:37.136175Z",
     "start_time": "2018-12-05T23:44:37.088696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________\n",
      "Classifier: MLP\n",
      "Accuracy: 0.7978290366350068\n",
      "AUC: 0.6204180187144386\n",
      "Precision: 0.13585858585858585\n",
      "Recall: 0.41770186335403725\n",
      "F1-score: 0.205030487804878\n",
      "______________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_true=np.array(test_results)[:,0]\n",
    "Y_pred=np.array(test_results)[:,1]\n",
    "display_metrics(\"MLP\",Y_pred,Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
